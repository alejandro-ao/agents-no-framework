{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models, also known as efficient language models or lightweight language models, have gained significant attention in recent years due to their importance in various applications. Here are some reasons why fast language models are crucial:\n",
      "\n",
      "1. **Scalability**: Fast language models can process large amounts of text data quickly, making them suitable for applications that require real-time processing, such as chatbots, virtual assistants, and language translation systems.\n",
      "2. **Resource Efficiency**: Traditional language models are computationally expensive and require significant resources (e.g., memory, CPU, and GPU). Fast language models, on the other hand, are designed to be lightweight and can run on lower-end hardware, making them more accessible to a wider range of users.\n",
      "3. **Edge Computing**: With the increasing adoption of edge computing, fast language models can be deployed on edge devices, such as smartphones, smart home devices, and IoT devices, enabling real-time processing and reducing latency.\n",
      "4. **Real-time Applications**: Fast language models are essential for real-time applications, such as:\n",
      "\t* Speech recognition: Fast language models can recognize spoken language in real-time, enabling applications like voice assistants and speech-to-text systems.\n",
      "\t* Language translation: Fast language models can translate text in real-time, making them suitable for applications like chatbots and language translation apps.\n",
      "\t* Sentiment analysis: Fast language models can analyze sentiment in real-time, enabling applications like social media monitoring and customer feedback analysis.\n",
      "5. **Improved User Experience**: Fast language models can provide a better user experience by:\n",
      "\t* Reducing latency: Fast language models can respond quickly to user input, reducing the time it takes to process and respond to user queries.\n",
      "\t* Enabling conversational interfaces: Fast language models can power conversational interfaces, such as chatbots and voice assistants, making it easier for users to interact with devices and services.\n",
      "6. **Advancements in AI**: Fast language models can accelerate the development of artificial intelligence (AI) and machine learning (ML) applications by:\n",
      "\t* Enabling faster training: Fast language models can be trained quickly, allowing researchers to iterate and improve AI and ML models faster.\n",
      "\t* Improving model accuracy: Fast language models can be used to fine-tune and improve the accuracy of AI and ML models, leading to better performance and decision-making.\n",
      "7. **Cost-Effective**: Fast language models can reduce costs by:\n",
      "\t* Reducing computational resources: Fast language models require less computational power, reducing the need for expensive hardware and infrastructure.\n",
      "\t* Enabling cloudless processing: Fast language models can be deployed on edge devices, reducing the need for cloud-based processing and associated costs.\n",
      "\n",
      "In summary, fast language models are crucial for various applications that require real-time processing, scalability, and resource efficiency. They can improve user experience, accelerate AI and ML development, and reduce costs, making them an essential component of modern language processing systems.\n"
     ]
    }
   ],
   "source": [
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"}\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, client: Groq, system: str = \"\") -> None:\n",
    "        self.client = client\n",
    "        self.system = system\n",
    "        self.messages: list = []\n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "\n",
    "    def __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"llama3-70b-8192\", messages=self.messages\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "get_planet_mass:\n",
    "e.g. get_planet_mass: Earth\n",
    "returns weight of the planet in kg\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the mass of Earth times 2?\n",
    "Thought: I need to find the mass of Earth\n",
    "Action: get_planet_mass: Earth\n",
    "PAUSE \n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 5.972e24\n",
    "\n",
    "Thought: I need to multiply this by 2\n",
    "Action: calculate: 5.972e24 * 2\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this: \n",
    "\n",
    "Observation: 1,1944×10e25\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def calculate(operation: str) -> float:\n",
    "    return eval(operation)\n",
    "\n",
    "\n",
    "def get_planet_mass(planet) -> float:\n",
    "    if planet == \"earth\":\n",
    "        return 5.972e24\n",
    "    if planet == \"mars\":\n",
    "        return 6.39e23\n",
    "    if planet == \"jupiter\":\n",
    "        return 1.898e27\n",
    "    if planet == \"saturn\":\n",
    "        return 5.683e26\n",
    "    if planet == \"uranus\":\n",
    "        return 8.681e25\n",
    "    if planet == \"neptune\":\n",
    "        return 1.024e26\n",
    "    if planet == \"mercury\":\n",
    "        return 3.285e23\n",
    "    if planet == \"venus\":\n",
    "        return 4.867e24\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "neil_tyson = Agent(client=client, system=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the mass of Mercury.\n"
     ]
    }
   ],
   "source": [
    "result = neil_tyson(\"What is the mass of Mercury times 5?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: get_planet_mass: Mercury \n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "result = neil_tyson()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.285e+23\n"
     ]
    }
   ],
   "source": [
    "result = get_planet_mass(\"mercury\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Observation: 3.285e+23'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(result)\n",
    "next_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to multiply this by 5.\n"
     ]
    }
   ],
   "source": [
    "result = neil_tyson(next_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: calculate: 3.285e23 * 5\n",
      "PAUSE\n"
     ]
    }
   ],
   "source": [
    "result = neil_tyson(next_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6425e+24\n"
     ]
    }
   ],
   "source": [
    "result = calculate(\"3.285e23 * 5\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Observation: 1.6425e+24'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_prompt = \"Observation: {}\".format(result)\n",
    "next_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: The mass of Mercury times 5 is 1.6425e+24.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = neil_tyson(next_prompt)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You run in a loop of Thought, Action, PAUSE, Observation.\n",
      "At the end of the loop you output an Answer\n",
      "Use Thought to describe your thoughts about the question you have been asked.\n",
      "Use Action to run one of the actions available to you - then return PAUSE.\n",
      "Observation will be the result of running those actions.\n",
      "\n",
      "Your available actions are:\n",
      "\n",
      "calculate:\n",
      "e.g. calculate: 4 * 7 / 3\n",
      "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
      "\n",
      "get_planet_mass:\n",
      "e.g. get_planet_mass: Earth\n",
      "returns weight of the planet in kg\n",
      "\n",
      "Example session:\n",
      "\n",
      "Question: What is the mass of Earth times 2?\n",
      "Thought: I need to find the mass of Earth\n",
      "Action: get_planet_mass: Earth\n",
      "PAUSE \n",
      "\n",
      "You will be called again with this:\n",
      "\n",
      "Observation: 5.972e24\n",
      "\n",
      "Thought: I need to multiply this by 2\n",
      "Action: calculate: 5.972e24 * 2\n",
      "PAUSE\n",
      "\n",
      "You will be called again with this: \n",
      "\n",
      "Observation: 1,1944×10e25\n",
      "\n",
      "If you have the answer, output it as the Answer.\n",
      "\n",
      "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
      "\n",
      "Now it's your turn:\n",
      "What is the mass of Mercury times 5?\n",
      "Thought: I need to find the mass of Mercury.\n",
      "Action: get_planet_mass: Mercury \n",
      "PAUSE\n",
      "Observation: 3.285e+23\n",
      "Thought: I need to multiply this by 5.\n",
      "Observation: 3.285e+23\n",
      "Action: calculate: 3.285e23 * 5\n",
      "PAUSE\n",
      "Observation: 1.6425e+24\n",
      "Answer: The mass of Mercury times 5 is 1.6425e+24.\n"
     ]
    }
   ],
   "source": [
    "for msg in neil_tyson.messages:\n",
    "    print(msg['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
